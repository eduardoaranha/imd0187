{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando nltk, e carregando suporte ao módulo da língua portuguesa\n",
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalhando com inglês\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr. John eats a lot.', 'He has a Ph.D. in food.']\n"
     ]
    }
   ],
   "source": [
    "# Extraindo sentenças em inglês\n",
    "text_en = \"Mr. John eats a lot. He has a Ph.D. in food.\"\n",
    "tokenized_sentences = nltk.sent_tokenize(text_en)\n",
    "print(tokenized_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr.', 'John', 'eats', 'a', 'lot', '.', 'He', 'has', 'a', 'Ph.D.', 'in', 'food', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(text_en)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalhando com português\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aquele é o sr. João Alves.', 'Ele tem Ph.D. em computação, não é?', 'Que bom!', 'Ele me disse “olá!” uma vez.']\n"
     ]
    }
   ],
   "source": [
    "# Extraindo sentenças em português\n",
    "text_pt = 'Aquele é o sr. João Alves. Ele tem Ph.D. em computação, não é? Que bom! Ele me disse “olá!” uma vez.'\n",
    "tokenized_sentences = nltk.sent_tokenize(text_pt)\n",
    "print(tokenized_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aquele', 'é', 'o', 'sr.', 'João', 'Alves', '.', 'Ele', 'tem', 'Ph.D.', 'em', 'computação', ',', 'não', 'é', '?', 'Que', 'bom', '!', 'Ele', 'me', 'disse', '“', 'olá', '!', '”', 'uma', 'vez', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(text_pt)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Meu email é e.m.a.i.l e CPF 032.233.232-95']\n",
      "['Meu', 'email', 'é', 'e.m.a.i.l', 'e', 'CPF', '032.233.232-95']\n"
     ]
    }
   ],
   "source": [
    "text_email_pt = 'Meu email é teste@teste.com e CPF 032.233.232-95'\n",
    "tokenized_sentences = nltk.sent_tokenize(text_email_pt)\n",
    "print(tokenized_sentences)\n",
    "tokens = nltk.word_tokenize(text_email_pt)\n",
    "print(tokens)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e876bd2ba7f66033916fe855677d8351f03a0df8f4d9fc4147f031fb68f1b0fb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pln')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
